{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as PD\n",
    "import numpy as NP\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import preprof      #my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(682, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import papers\n",
    "csv = '/Users/cdw/Desktop/pkpd_script/MNCA_ANALYSIS/ready_processed_2.csv'\n",
    "papers=PD.read_csv(csv)\n",
    "\n",
    "# select only relevant papers\n",
    "relevant = ['Non-compartmental','Modelling']\n",
    "relevant_papers = papers.loc[papers['category'].isin(relevant)]\n",
    "relevant_papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#NCA: 239\n",
      "#Modelling: 443\n"
     ]
    }
   ],
   "source": [
    "num_nca=relevant_papers.loc[papers['category']=='Non-compartmental'].shape[0]\n",
    "num_mod=relevant_papers.loc[papers['category']=='Modelling'].shape[0]\n",
    "print('#NCA: {}'.format(num_nca))\n",
    "print('#Modelling: {}'.format(num_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_seed = 61097\n",
    "x = [a.split('!$!') for a in relevant_papers.loc[:,'words']]\n",
    "y = relevant_papers.loc[:,'category']\n",
    "\n",
    "def fake_tokeniser(text):\n",
    "    return text\n",
    "\n",
    "tf_idf = TfidfVectorizer(analyzer='word',tokenizer=fake_tokeniser,preprocessor=fake_tokeniser,lowercase=False,token_pattern=None)\n",
    "\n",
    "tfidf = tf_idf.fit_transform(x)\n",
    "tfidf = PD.DataFrame(tfidf.toarray())\n",
    "tfidf_names = tf_idf.get_feature_names()\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(tfidf,y,test_size=0.15,random_state=rd_seed,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearSVC(random_state=61097,max_iter=10000).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "impts = abs(model.coef_[0])\n",
    "my_dt = PD.DataFrame(impts)\n",
    "importances = [i[0] for i in my_dt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ind = []\n",
    "\n",
    "def find(s, c1):\n",
    "    return [i for i, c2 in enumerate(s) if c2 == c1]\n",
    "\n",
    "\n",
    "for x in importances:\n",
    "    if x >= 0.33:\n",
    "        inds=find(importances,x)\n",
    "        for i in inds:\n",
    "            tr_ind.append(i)\n",
    "tr_ind=list(set(tr_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "print(len(tr_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579, 320) (103, 320)\n"
     ]
    }
   ],
   "source": [
    "x_train= x_train.iloc[:,tr_ind]\n",
    "x_test = x_test.iloc[:,tr_ind]\n",
    "\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before hyperparam tuning...\n",
      "acc: 0.87379    f1:0.82192\n"
     ]
    }
   ],
   "source": [
    "original_model=LinearSVC(random_state=61097,max_iter=10000).fit(x_train,y_train)\n",
    "original_pred=original_model.predict(x_test)\n",
    "original_acc=accuracy_score(y_test,original_pred)\n",
    "original_f1=f1_score(y_test,original_pred,pos_label='Non-compartmental')\n",
    "\n",
    "print('Before hyperparam tuning...')\n",
    "print(f'acc: {round(original_acc,5)}    f1:{round(original_f1,5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameter tuning: linear svc tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_=LinearSVC(random_state=61097,max_iter=10000).fit(x_train,y_train)\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "param_grid={'C':Cs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 92.4\n",
      "Best Params: {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(model_, param_grid, cv=5)\n",
    "grid_result=grid_search.fit(x_train, y_train)\n",
    "\n",
    "print('Best Score:', round(grid_result.best_score_*100,2))\n",
    "print('Best Params:', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8640776699029126\n",
      "0.8157894736842106\n"
     ]
    }
   ],
   "source": [
    "testmod=LinearSVC(max_iter=10000,random_state=61097,C=10).fit(x_train,y_train)\n",
    "y_pred=testmod.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(f1_score(y_test,y_pred,pos_label='Non-compartmental'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### any tuning makes the model worse..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we will stick to the default model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so in the end...\n",
      "acc: 0.87379    f1:0.82192\n"
     ]
    }
   ],
   "source": [
    "print('so in the end...')\n",
    "print(f'acc: {round(original_acc,5)}    f1:{round(original_f1,5)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
