{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as PD\n",
    "import numpy as NP\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import preprof         #my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD IN DATA\n",
    "\n",
    "#directory = '/Users/cdw/Desktop/pkpd_script/LABELLED/COMPLETE/'\n",
    "#preprof.generate_allcsv(directory,'all.csv')\n",
    "#csv= '/Users/cdw/Desktop/pkpd_script/all.csv'\n",
    "\n",
    "csv = '/Users/cdw/Desktop/pkpd_script/MNCA_ANALYSIS/ready_processed_2.csv'\n",
    "papers=PD.read_csv(csv)\n",
    "relevant = ['Non-compartmental','Modelling']\n",
    "relevant_papers = papers.loc[papers['category'].isin(relevant)]\n",
    "\n",
    "x = [a.split('!$!') for a in relevant_papers.loc[:,'words']]\n",
    "y = relevant_papers.loc[:,'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURE ENGINEERING\n",
    "\n",
    "def fake_tokeniser(text):\n",
    "    return text\n",
    "\n",
    "tf_idf = TfidfVectorizer(analyzer='word',\n",
    "                         tokenizer=fake_tokeniser,\n",
    "                         preprocessor=fake_tokeniser,\n",
    "                         lowercase=False,\n",
    "                         token_pattern=None)\n",
    "bag_of_words = CountVectorizer(analyzer='word',\n",
    "                               tokenizer=fake_tokeniser,\n",
    "                               preprocessor=fake_tokeniser,\n",
    "                               lowercase=False,\n",
    "                               token_pattern=None)\n",
    "\n",
    "def wm2df(wm, feat_names):  \n",
    "    doc_names = [f'Doc{idx}' for idx, _ in enumerate(wm)]\n",
    "    df = PD.DataFrame(data=wm.toarray(), index=doc_names,\n",
    "                      columns=feat_names)\n",
    "    return(df)\n",
    "\n",
    "tfidf = tf_idf.fit_transform(x)\n",
    "tfidf_names = tf_idf.get_feature_names()\n",
    "\n",
    "bow=bag_of_words.fit_transform(x)\n",
    "bow_names=bag_of_words.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove characters '[', ']' and '>' as xgboost doesn't allow them in feature names\n",
    "\n",
    "def remove_chars(feature_names):\n",
    "    new_feature_list=[]\n",
    "    for name in feature_names:\n",
    "        if '[' in name:\n",
    "            ind=name.index('[')\n",
    "            name=name[:ind]+name[ind+1:]\n",
    "        if ']' in name:\n",
    "            ind=name.index(']')\n",
    "            name=name[:ind]+name[ind+1:]\n",
    "        if '>' in name:\n",
    "            ind=name.index('>')\n",
    "            name=name[:ind]+name[ind+1:]\n",
    "        new_feature_list.append(name)\n",
    "    return new_feature_list\n",
    "\n",
    "tfidf_names_fixed=remove_chars(tfidf_names)\n",
    "bow_names_fixed=remove_chars(bow_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................."
     ]
    }
   ],
   "source": [
    "## change names of duplicate features\n",
    "\n",
    "def change_dups(features_fixed):\n",
    "    counter=0\n",
    "    for feature in features_fixed:\n",
    "        counter+=1\n",
    "        if counter%1000==0:\n",
    "            print('.',end='')\n",
    "        if features_fixed.count(feature)>1:\n",
    "            print('-',end='')\n",
    "            index_1=features_fixed.index(feature)\n",
    "            features_fixed[index_1]+='_1'\n",
    "            index_2=features_fixed.index(feature)\n",
    "            features_fixed[index_2]+='_2'\n",
    "            try:\n",
    "                index_3=features_fixed.index(feature)\n",
    "                features_fixed[index_3]+='_3'\n",
    "            except: pass\n",
    "            try:\n",
    "                index_4=features_fixed.index(feature)\n",
    "                features_fixed[index_4]+='_4'\n",
    "            except: pass\n",
    "    return features_fixed\n",
    "\n",
    "tfidf_names_fixed=change_dups(tfidf_names_fixed)\n",
    "bow_names_fixed=change_dups(bow_names_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop trickly column\n",
    "## we  can do this becuase its feature importance is 0\n",
    "\n",
    "tfidf_matrix = wm2df(tfidf,tfidf_names_fixed)\n",
    "#tfidf_matrix=tfidf_matrix.drop(columns='(1r,9s,12s,13r,14s,17r,18e,21s,23s,24r,25s,27r)-1,14-dihydroxy-12-(e)-2-(1r,3r,4r)-4-hydroxy-3-methoxycyclohexyl-1-methylvinyl-23,25-dimethoxy-13,19,21,27-tetramethyl-17-(2-oxopropyl)-11,28-dioxa-4-azatricyclo[22.3.1.0(4.9)]octacos-18-ene-2,3,10,16-tetroneT')\n",
    "bow_matrix=wm2df(bow,bow_names_fixed)\n",
    "#bow_matrix=bow_matrix.drop(columns='(1r,9s,12s,13r,14s,17r,18e,21s,23s,24r,25s,27r)-1,14-dihydroxy-12-(e)-2-(1r,3r,4r)-4-hydroxy-3-methoxycyclohexyl-1-methylvinyl-23,25-dimethoxy-13,19,21,27-tetramethyl-17-(2-oxopropyl)-11,28-dioxa-4-azatricyclo[22.3.1.0(4.9)]octacos-18-ene-2,3,10,16-tetroneT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bow_matrix,open('bow_matrix','wb'))\n",
    "pickle.dump(bow_matrix,open('tfidf_matrix','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
